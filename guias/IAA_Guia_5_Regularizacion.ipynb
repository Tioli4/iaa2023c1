{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X1ivfc2UQjWH"
      },
      "source": [
        "# Regularización"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8ydKVFDYQjWI"
      },
      "source": [
        "En la clase pasada observamos como aumentando el grado del polinomio, obtenemos modelos mas flexibles que logran ajustar mejor los datos de entrenamiento. Sin embargo, esta mejora generaba fronteras de decisión más complejas que generalizaban peor, y la performance del conjunto de test empeoraba. Este fenómeno es lo que se conoce como **sobreajuste**: Es el punto en el que nuestro modelo comienza a ajustar no solo el _patrón_ de los datos de entrenamiento, sino también el _ruido_ aleatorio que hay en ellos, y deteriora el poder predictivo.\n",
        "\n",
        "La forma de combatir este problema es disminuir la flexiblidad del modelo, lo que se conoce como **regularización**. Esto se hace eligiendo apropiadamente los hiperparámetros que determinan la flexibilidad (en nuestro caso, el grado del polinomio). \n",
        "\n",
        "Una forma sistemática de elegir los hiperparámetros es monitorear la performance del modelo sobre un conjunto de datos que no ha visto anteriormente, al que llamaremos _validación_, y elegir los hiperparámetros (en este caso, el grado del polinomio) que resultan en el modelo que mejor generaliza a este conjunto. \n",
        "\n",
        "Así como los parámetros del modelo se ajustan para mejorar la performance en el conjunto de entrenamiento, los hiperparámetros lo hacen para mejorar la performance en el conjunto de validación. Por este motivo, es de esperar que la performance sobre estos conjuntos este sobre-estimada, y para tener una medida objetiva sobre nuestro modelo final reservamos un conjunto de _evaluación_ (o _test_) que no será utilizado para tomar ninguna decisión. \n",
        "\n",
        "En este notebook visitaremos el problema de la clase anterior, y separaremos el dataset en tres partes:\n",
        "- Entrenamiento\n",
        "- Validación\n",
        "- Evaluación\n",
        "\n",
        "De esta forma encontraremos sistemáticamente el grado óptimo para nuestro modelo de regresión logística polinomial. Luego, introduciremos las técnicas más genéricas de regularización L1, L2 y ElasticNet, y aplicaremos el mismo método para encontrar el modelo óptimo.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lVwg4YvRQjWJ"
      },
      "source": [
        "## Utils\n",
        "Misma función utilitaria que la clase anterior."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_dDjTuRDQjWJ"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import sklearn\n",
        "\n",
        "def plot_regions(classifier, x, t):\n",
        "    \"\"\"Plot results from classification.\"\"\"\n",
        "    plt.figure(figsize=(9, 7))\n",
        "\n",
        "    xx, yy = np.meshgrid(np.linspace(x[:, 0].min()-1, x[:, 0].max()+1, 200),\n",
        "                         np.linspace(x[:, 1].min()-1, x[:, 1].max()+1, 200))\n",
        "\n",
        "    # evaluate decision function\n",
        "    Z = classifier.decision_function(np.c_[xx.ravel(), yy.ravel()])\n",
        "    Z = Z.reshape(xx.shape)\n",
        "    # colour regions\n",
        "    plt.pcolormesh(xx, yy, Z<0, cmap=plt.cm.bwr, shading='auto', alpha=0.4)\n",
        "    # decision boundary\n",
        "    plt.contour(xx, yy, 1/(1 + np.exp(-Z)), [0.05, 0.5, 0.95], colors=['0.5', 'k', '0.5'], zorder=1)\n",
        "\n",
        "    xc1 = x[t == np.unique(t.flatten()).max()]\n",
        "    xc2 = x[t == np.unique(t.flatten()).min()]\n",
        "\n",
        "    plt.plot(*xc1.T, 'ob', mfc='None', label='C1')\n",
        "    plt.plot(*xc2.T, 'or', mfc='None', label='C2')\n",
        "\n",
        "    # Remove ticks\n",
        "    plt.xticks(())\n",
        "    plt.yticks(())\n",
        "    plt.axis('tight')\n",
        "\n",
        "    return\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YtypLj0eQjWK"
      },
      "source": [
        "## Dataset\n",
        "Corra la siguiente línea para generar un dataset como el de la clase anterior. Esta vez, generaremos 60 puntos extra que serán destinados a evaluación."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LDEeGsLOQjWK"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from sklearn.datasets import make_moons\n",
        "X, y = make_moons(360, noise=0.25, random_state=42)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fm5ldZy3QjWK"
      },
      "source": [
        "## Ejercicio 1\n",
        "- Separe el dataset, utilizando el método `train_test_split` de scikit-learn, en:\n",
        "    - Entrenamiento (240)\n",
        "    - Validación (60)\n",
        "    - Evaluación (60)\n",
        "- Grafique en un plano los tres conjuntos."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1ZtJxs2sQjWK"
      },
      "outputs": [],
      "source": [
        "# Tu turno...\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "amn23vJMQjWK"
      },
      "source": [
        "## Ejercicio 2\n",
        "\n",
        "- Defina una función que dado el grado del polinomio, devuelve un `Pipeline` consistente de un pre-procesado polinómico y un regresor logístico (usando `penalty='none'`). Opcionalmente puede introducir un `StandardScaler` como paso intermedio\n",
        "- Itere sobre los grados polinóomicos de 1 a 10, fiteando un regresor polinómico sobre el conjunto de entrenamiento. Guarde en arrays su exactitud sobre los conjuntos de entrenamiento y validación.\n",
        "- Plotee los arrays de exactitud sobre los conjuntos de entrenamiento y validación en función del grado polinómico.\n",
        "- Encuentre el grado polinómico que maximiza la exactitud de validación.\n",
        "- Entrene un regresor polinómico del grado óptimo encontrado sobre el dataset extendido de entrenamiento+validación. Este es su modelo final.\n",
        "- Mida la exactitud del modelo final sobre el conjunto de evaluación.\n",
        "- Opcional: Grafique la frontera de decisión."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rrk3yGmEQjWK"
      },
      "outputs": [],
      "source": [
        "# Tu turno...\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vlrq9tstQjWK"
      },
      "source": [
        "## Regularización"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Jnn2H_hQjWK"
      },
      "source": [
        "## Ejercicio 3\n",
        "- Elija un tipo de regularización (L1 o L2)\n",
        "- Modifique la función del ejercicio anterior para que acepte como parametros el argumento `C` e inicialice el regresor logístico con ese parámetro y el `penalty` correspondiente a la regularización escogida.\n",
        "- Entrene y compare las fronteras de decisión de los siguientes regresores logísticos polinómicos (del grado óptimo obtenido en el ejericio 2):\n",
        "    - sin regularizar (`penalty='none'` o bien `C=1e16`)\n",
        "    - medianamente regularizado (`C~1`)\n",
        "    - altamente regularizado (`C ≤ 0.001`)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C3mM1ehfQjWL",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "# Tu turno...\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IZgFXjppQjWL"
      },
      "source": [
        "## Ejercicio 4\n",
        "\n",
        "- Defina una grilla de hiperparámetros (para `C` y `degree`).\n",
        "- Entrene (sobre el conjunto de entrenamiento) regresores logísticos polinómicos para cada combinación de hiperparámetros de la grilla, registrando sus exactitudes sobre el conjunto de validación.\n",
        "- Encuentre la combinación de hiperparámetros óptima para este modelo y dataset\n",
        "- Entrene el modelo óptimo sobre el conjunto extendido de entrenamiento + validación.\n",
        "- Mida la exactitud de este modelo final sobre el conjunto de evaluación. Compare con la obtenida en el Ejercicio 2.\n",
        "- Opcional: Grafique la frontera de decisión.\n",
        "\n",
        "_Pista:_ \n",
        "- _Para hacerlo simple, considere dos bucles anidados._"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B2j9KgZnQjWL"
      },
      "outputs": [],
      "source": [
        "# Tu turno...\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sEAFsAcfQjWL"
      },
      "source": [
        "## Ejercicio 5: Regresión"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1CSylk28R9R9"
      },
      "source": [
        "En la [guía 2](https://github.com/LCD-UNSAM/iaa2023c1/blob/main/guias/IAA_Guia_2_RegresionLineal_Ejercitacion.ipynb) se le pidió que realice un ajuste lineal para un caso de regresión. Repita el ejercicio, pero ahora en vez de utilizar la clase `sklearn.linear_model.LinearRegression`, utilice alguna(s) de las siguientes:\n",
        "- `sklearn.linear_model.Ridge`: Regresión lineal que implementa la regularización L2\n",
        "- `sklearn.linear_model.Lasso`: Regresión lineal que implementa la regularización L1\n",
        "- `sklearn.linear_model.ElasticNet`: Regresión lineal que implementa la regularización ElasticNet (una combinación lineal de L1 y L2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eHJ7FT8pR9Ay"
      },
      "outputs": [],
      "source": [
        "# Tu turno...\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "k2zriCxcSJcP"
      },
      "source": [
        "### Formulario de asistencia\n",
        "Por favor, no olviden completar el siguiente formulario antes del miércoles 26/04 a la 23:59.\n",
        "\n",
        "https://forms.gle/EswyadMHbhj6SVj88"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.6"
    },
    "vscode": {
      "interpreter": {
        "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
