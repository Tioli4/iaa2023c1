{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Guía 2 - Regresión Lineal - Extras\n",
    "\n",
    "#### Dataset Sintético\n",
    "\n",
    "Generamos el mismo dataset sintético que utilizamos en el otro notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(2022)\n",
    "\n",
    "n = 1000\n",
    "X = np.linspace(-2,3,n)\n",
    "y_real = 3*X - 2\n",
    "\n",
    "alpha = 1\n",
    "y = y_real + alpha*np.random.randn(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(X,y, s=2, alpha=0.5, label='Datos Medidos')\n",
    "plt.plot(X, y_real, '--',label='Curva Teórica', c='r')\n",
    "plt.xlabel('X')\n",
    "plt.ylabel('y')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La siguiente parte del notebook es igual a la guía, con unos extras a continuación.\n",
    "\n",
    "### 1. Regresión lineal con SciPy\n",
    "\n",
    "Ahora vamos a hacer como si no conociéramos la relación entre $X$ e $y$ - nos olvidamos por un rato que sabemos cómo se generaron los datos - e intentaremos obtener la pendiente y ordenada al origen. Estos experimentos, donde generamos datos de una manera controlada, suelen ser muy útiles para familiarizarse con nuevos modelos y metodologías. De hecho, muchos paquetes, por ejemplo Scikit-Learn, vienen con funcionalidades para generar datasets sintéticos.\n",
    "\n",
    "Para obtener los parámetros vamos a utilizar SciPy. Por ahora no entraremos en detalles sobre cómo funciona, solamente lo utilizaremos. Recomendamos consultar la [documentación de la función `stats.linregress`](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.linregress.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = stats.linregress(X,y)\n",
    "res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para los que estén acostumbrados a trabajar con R, verán que estos resultados son muy parecidos a los que suelen encontrar. Devuelve la pendiente `slope`, la ordenada al origen `intercept`, el `rvalue`, el `pvalue`, la desviación estándar de la estimación de la pendiente`stderr` y la desviación estándar de la estimación de la ordenada al origen, `intercept_stderr`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(res.slope)\n",
    "print(res.intercept)\n",
    "print(res.rvalue)\n",
    "print(res.pvalue)\n",
    "print(res.stderr)\n",
    "print(res.intercept_stderr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "¿Qué son esos valores? Los dos primeros son autoexplicativos, son los parámetros que buscamos. Están bastante cerca de los valores reales (3.01 vs 3, -1.99 vs -2). \n",
    "\n",
    "Veamos el resultado gráficamente:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(X,y, s=2, alpha=0.5, label='Datos Medidos')\n",
    "plt.plot(X, y_real, '--',label='Curva Teórica', c='r')\n",
    "plt.plot(X, X*res.slope + res.intercept, '--', lw=2, label='Curva Obtenida (SciPy)', c='g')\n",
    "\n",
    "plt.xlabel('X')\n",
    "plt.ylabel('y')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El ajuste parece ser muy bueno. ¿Estás de acuerdo?\n",
    "\n",
    "**Ejercicio:** modificar los valores de `n` y `alpha` un par de veces (a mano) y observar cómo se modifican esos valores.\n",
    "\n",
    "Veamos el resto de los coeficientes que mencionamos qué son.\n",
    "\n",
    "**Coeficiente de Determinación ($R^2$ o $r^2$)**\n",
    "\n",
    "`rvalue` corresponde al coeficiente de determinación. No mostraremos acá cómo se calcula, pero sí mencionaremos que - salvo raras excepciones - su valor está entre 0 y 1. Esté último valor indica que el ajuste lineal es un modelo que logra explicar perfectamente los datos, mientras que 0 indica que el modelo no logra explicar la relación entre nuestros datos ($X$ e $y$ en este caso).\n",
    "\n",
    "**p-value**\n",
    "\n",
    "No entraremos en detalles sobre el significado específico del `pvalue`, ya que excede los alcances de la materia - y lo van a ver bien cuando cursen las materias de probabilidad estadística. Por ahora diremos que es un valor que está asociado a la probabilidad de que el resultado observado se deba al azar. Es decir, de alguna forma indica la probabilidad de que la relación lineal encontrada no sea cierta y que se deba a una simple coincidencia azarosa. **OJO: existen muchas sutilezas con respecto al p-value. Tomar con cuidado este párrafo.**\n",
    "\n",
    "**Desviaciones Estándar**\n",
    "\n",
    "Las desviaciones estándar `stderr` e `intercept_stderr` son parámetros que nos sirven para calcular intervalos de confianza para la estimación de la pendiente y la ordenada al origen. Ya hemos visto que los valores obtenidos están cerca de los valores reales (3.01 vs 3, -1.99 vs -2). Pero, ¿qué es *cerca*?¿Y qué podemos hacer cuando no conocemos los valores reales, que es la gran mayoría de las veces? `stderr` e `intercept_stderr` sirven para obtener intervalos de confianza, es decir rangos de posibles valores donde se encuentra el verdadero valor de la pendiente y la ordenada al origen. Por ejemplo, es posible estimar intervalos de confianza donde el 95% de las veces se encuentra el verdadero valor de la siguiente forma:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts = 2 ## Este dos es una aproximacion. Su calculo es un poco mas complejo, pero excede el alcance de la materia.\n",
    "\n",
    "print(f\"Pendiente (95%): {res.slope:.6f} +/- {ts*res.stderr:.6f}\")\n",
    "print(f\"Ordenada al origen (95%): {res.intercept:.6f} +/- {ts*res.intercept_stderr:.6f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notar que, dentro de esos intervalos, se encuentra el verdadero valor que habíamos elegido.\n",
    "\n",
    "**Ejercicio (opcional para cuando terminen de leer el notebook):** obtener un gráfico para cada una de las siguientes variables en función de `alpha` para `n=1000`.\n",
    "* `slope`\n",
    "* `intercept`\n",
    "* `rvalue`\n",
    "* `pvalue`\n",
    "* `stderr`\n",
    "* `intercept_stderr`\n",
    "\n",
    "Interpretar dado lo que saben hasta ahora."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "COMPLETAR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "COMPLETAR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 2. Interpolación y Extrapolación\n",
    "\n",
    "**Ejercicio:** Estudia el siguiente código e interpreta su resultado. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 100\n",
    "X = np.linspace(-3,3,n)\n",
    "y_real = 3*X - 2\n",
    "alpha = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_new = np.linspace(-8,8,n)\n",
    "for i in range(100):\n",
    "    y = y_real + alpha*np.random.randn(n)\n",
    "    linear_model = LinearRegression()\n",
    "    linear_model.fit(X.reshape(-1,1), y)\n",
    "    y_pred = linear_model.predict(X_new.reshape(-1,1))\n",
    "    \n",
    "    plt.plot(X_new, y_pred, c='g', alpha=0.25)\n",
    "\n",
    "plt.scatter(X, y,label='Datos Medidos (un ejemplo)', alpha=0.1)\n",
    "plt.plot(X, y_real, '--',label='Curva Teórica', c='r')\n",
    "plt.xlabel('X')\n",
    "plt.ylabel('y')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Ajuste de una regresión lineal\n",
    "\n",
    "¿Cómo se ajusta una regresión lineal? Es decir, ¿cuál es la maquinaria interna detrás de `stats.linregress` o el `.fit(X,y)` del modelo lineal de Scikit-Learn? Mencionaremos algunos de los puntos principales que debes tener en cuenta:\n",
    "\n",
    "En primer lugar, ten en cuenta que ajustar un modelo lineal implica encontrar los parámetros - ordenada y pendientes - que hacen que el modelo lineal mejor aproxime a nuestro datos. Si bien esto puede parecer redundante, es importante recalcarlo. Porque, en principio, debemos definir a qué nos referimos con \"mejor\": esto implica definir una función de costo. La función de costo es, en muchos casos, el error cuadrático medio. Es decir, buscamos los parámetros que minimizan el error cuadrático medio dentro de todos los modelos lineales posibles. Por ejemplo, para el caso con un solo atributo, recordemos que\n",
    "\n",
    "$$Y \\approx \\beta_0 + \\beta_1 X,$$\n",
    "\n",
    "Para una $x_i$ particular, la predicción es $\\hat y_i = \\beta_0 + \\beta_1 x_i$.\n",
    "\n",
    "El error cuadrático medio era\n",
    "\n",
    "$$ MSE(y, \\hat y) = \\frac{1}{N}\\sum_{i=1}^N (y_i - \\hat y_i)^2.$$\n",
    "\n",
    "Entonces, combinando ambas cosas, queda que\n",
    "\n",
    "$$ MSE(\\beta_0, \\beta_1) = \\frac{1}{N}\\sum_{i=1}^N (y_i - (\\beta_0 + \\beta_1 x_i))^2.$$\n",
    "\n",
    "Notar que esta función depende de los coeficientes del modelo lineal. Entonces, es un problema de minimización como los que vieron (o verán) en Análisis Matemático. No hay una única forma de obtener estos coeficientes. Existen formas analíticas y formas aproximadas. En algunos casos, la forma analítica es imposible de calcular, por lo que se debe recurrir las formas aproximadas."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
