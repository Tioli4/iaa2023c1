{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clasificación Binaria"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los algoritmos de aprendizaje supervisado consisten en aprender un _mapa_ entre las variables características de los datos (_features_) y la variable objetivo (_target_). La meta es que el modelo ya entrenado pueda ser usado con nuevas observaciones de los features para predecir el target. Por este motivo, este tipo de algoritmos suele ser dividido gruesamente en dos categorias:\n",
    "- Regresión: Cuando el(los) target(s) es continuo (como un numero real)\n",
    "- Clasificación: Cuando el(los) target(s) es discreto (como una clase o categoría)\n",
    "\n",
    "Las tareas de clasificación son luego subdivididas de acuerdo a cuantos targets uno intena predecir (_mono-target_ vs _multi-target_) y cuantos valores, o _clases_, puede tomar (binario vs multi-clase).\n",
    "\n",
    "En la clase pasada vimos como acercarnos a problemas de Regresión usando modelos lineales. Hoy abordaremos los conceptos principales de tareas de Clasificación, considerando un problema simple de Clasificación Binaria de un solo target, al cual nos aproximaremos de una forma muy similar."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Librerias\n",
    "\n",
    "Como en todo proyecto, utilizaremos muchas funcionalidades disponibles en librerias abiertas. Para importarlas en el ambiente de trabajo, corre la siguiente celda:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Funcionalidades para trabajar con datos estructurados en forma de Dataframes\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Set de datos\n",
    "\n",
    "Para mostrar de forma clara los conceptos, utilizaremos un dataset artificial. Este consiste en dos variables ($x$ e $y$) que identifican un punto en el plano. Estos puntos pueden pertenecer a dos clases diferentes ($target = 0$ o $1$).\n",
    "\n",
    "La siguiente línea de codigo descargará el dataset a tu sistema local de archivos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "! wget https://raw.githubusercontent.com/LCD-UNSAM/iaa2023c1/main/datasets/binary_classification.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ejercicio**\n",
    "- Importa los datos en el archivo `BinaryClassification1.csv` a un DataFrame de Pandas y visuliza las primersa filas.\n",
    "\n",
    "*Pista: Prueba corriendo* `pd.read_csv?` y `pd.DataFrame.head?` y lee la documentación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tu turno...\n",
    "#df = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ejercicio**\n",
    "- Grafica los datos usando la función `.plot`\n",
    "- Explora visualizar las clases pintando los puntos de diferente color.\n",
    "\n",
    "*Pistas:*\n",
    "- *Usa `kind=scatter` para graficar puntos sueltos.*\n",
    "- *El argumento `c` de la función `DataFrame.plot` se puede usar para especificar la columna que lleva informacion del color*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tu turno...\n",
    "#df.plot(...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Primer Acercamiento a la clasificacion: Caso unidimensional."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imaginemos que queremos clasificar este conjunto de datos en las dos clases provistas, utilizando solo la información de una variable, por ejemplo $x$. El acercamiento mas sencillo consistiría en:\n",
    "- Establecer un valor de _umbral_ $x_u$\n",
    "- Clasificar segun si $x>x_u$\n",
    "\n",
    "Distintos valores de $x_u$ daran lugar a distintos resultados. Para medir que tan bueno o malo es el resultado, necesitamos de una metrica. Una metrica popular para clasificacion binaria de conjuntos de datos _balanceados_ (es decir, con similar cantidad de instancias en cada clase) es la _exactitud_ o _accuracy_. Esta no es otra cosa que la fracción de instancias bien clasificadas.\n",
    "\n",
    "**Ejercicio**\n",
    "- Grafique un histograma de la coordenada $x$ para cada clase. \n",
    "- Elija (a ojo) un valor de umbral $x_u$ \n",
    "- Cree un vector con sus predicciones $pred$, y mida cual es la exactitud de su predicción.\n",
    "- Pruebe con distintos valores de umbral, tambien puede probar el mismo procedimiento en la variable $y$. ¿Cual es el mejor _modelo_ que obtiene?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Tu turno...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Debajo hay un snippet para visualizar esta clasificación en el gráfico bidimensional. Asegúrate que el vector de predicciones se llama `pred`, el umbral elegido `x_u`, y el DataFrame `df` contenga las columnas originales `x`, `y` y `target`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(df[df.target==0].x, df[df.target==0].y, marker='o', c=pred[df.target==0], label='Class 0')\n",
    "plt.scatter(df[df.target==1].x, df[df.target==1].y, marker='v', c=pred[df.target==1], label='Class 1')\n",
    "plt.legend()\n",
    "plt.vlines(x_u,df.y.min(), df.y.max(), ls='-.', colors='black')\n",
    "plt.xlabel(\"x\")\n",
    "plt.ylabel(\"y\")\n",
    "plt.legend"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Segundo acercamiento: Caso bi(multi)-dimensional"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los modelos lineales de clasificación consisten en esto: Trazar una línea recta que divida de un lado una clase y de otro lado otra. En el caso de mas de 2 dimensiones, es colocar un hiperplano que divida el espacio en dos mitades: A un lado y el otro del hiperplano, clasificamos como una u otra clase. \n",
    "\n",
    "La manera matemática de caracterizar una linea recta en un plano es con una simple ecuación:\n",
    "$$\n",
    "w_1  x + w_2 y = cte\n",
    "$$\n",
    "donde $w_1$ y $w_2$ determinan el angulo de la linea, y la constante mueve paralelamente esa recta. Esta constante no es otra cosa que el _umbral_ que elegimos en la sección anterior ($x_u$), mientras que los numeros $w_i$ se le llaman _pesos_ y en el caso de una dimensión de la sección anterior corresponde a tomar $w_2=0$ y $w_1=1$ (una linea vertical).\n",
    "\n",
    "En el caso mas general de $N$ dimensiones, generaliza de igual forma:\n",
    "$$\n",
    "w_0 + w_1  x_1 + w_2 x_2 + ... + w_N  x_N = 0\n",
    "$$\n",
    "(donde llamamos al umbral $-w_0$ para llevar la ecuación a una forma convencional).\n",
    "\n",
    "- Al hiperplano que separa los puntos se le llama **_\"frontera de decisión\"_**. \n",
    "\n",
    "- Este esta caracterizado por ser donde se anula la función lineal $f(\\vec w, \\vec x) = w_0 + w_1  x_1 + w_2 x_2 + ... + w_N  x_N $\n",
    "\n",
    "- A la función usada para clasificar se le llama **función discriminante**.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ejericio**\n",
    "Utilice las funciones definidas debajo para encontrar la mejor frontera de decisión."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def model(w, x, y):\n",
    "    return w[0] +w[1]*x + w[2]*y > 0\n",
    "\n",
    "def plot(x, y, target, pred, w=[]):\n",
    "\n",
    "    plt.scatter(x[target==0], y[target==0], marker='o', c=np.where(pred[target==0], 'r', 'b'), label='Class 0')\n",
    "    plt.scatter(x[target==1], y[target==1], marker='v', c=np.where(pred[target==1], 'r', 'b'), label='Class 1')\n",
    "    plt.legend()\n",
    "    if len(w) >= 3 and (w[2]!=0 or w[1]!=0):\n",
    "        if w[2]==0:\n",
    "            plt.vlines(-w[0]/w[1],df.y.min(), df.y.max(), ls='-.', colors='black')\n",
    "        else:\n",
    "            u = np.linspace(min(x), max(x), 100)\n",
    "            v = -(w[0] + w[1]*u) / w[2]\n",
    "            plt.plot(u,v, ls='-.', c='black')        \n",
    "    plt.xlabel(\"x\")\n",
    "    plt.ylabel(\"y\")\n",
    "    plt.legend()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Tu turno...\n",
    "w =[\n",
    "    0, #w0\n",
    "    0, #w1\n",
    "    0, #w2\n",
    "    ]\n",
    "\n",
    "preds = model(w, df.x, df.y)\n",
    "plot(df.x, df.y, df.target, preds, w=w)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este es el mas sencillo de los métodos llamados de _función discriminante_. Estos consisten en ajustar una función escalar, cuyo valor determina la clase a la que pertenece, dependiendo de si está por encima o debajo del _umbral de decisión_.\n",
    "\n",
    "A esta función lineal, cuando se aparea con un método particular para elegir los pesos $w$, se le llama _modelo_. Un caso particular es el llamado _Perceptrón_ que corresponde a elegir el $w$ que minimice el número de puntos mal clasificados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Opcional] Un poco de teoría: Función de Pérdida"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como vemos, los modelos de machine learning no son mas que parametrizaciones de como tomar una decisión. En el caso de modelos lineales, tomamos una combinacion lineal de todos nuestros features, cuyos coeficientes (los pesos $w$) son los parámetros del modelo. \n",
    "\n",
    "El procedimiento de **_entrenar_** un modelo consiste en encontrar cual es la _mejor_ combinación de parámetros de un modelo sobre un dataset. Lo unico que nos falta es definir que significa \"mejor\", para esto es que se usa una _función de pérdida_. Esta es una función que toma las predicciones $p$ de nuestro modelo (que a su vez depende de los parámetros $\\vec w$ y los features del dataset $X$) y el objetivo o target $t$, y devuelve un número que nos dice que tan _lejos_ esta el modelo de predecir bien: \n",
    "$$ \\mathcal{L} = \\mathcal{L}(p, t) = f(\\vec w, X, \\vec t).$$ \n",
    "\n",
    "El problema de entrenamiento pasa a ser un problema de _optimización_: Dado $X$ y $\\vec t$, encontrar los $\\vec w$ que minimizan la función de pérdida $\\mathcal{L}$. $$\\vec w_{best} = \\left. \\argmin_{\\vec w} \\mathcal{L} (\\vec p, \\vec t) \\right|_{X, \\vec t}$$\n",
    "Afortunadamente, este problema de optimización es uno de los mas estudiados en ciencias de la computación y hoy en dia contamos con algoritmos muy eficientes para su resolución.\n",
    "\n",
    "Entre las posibles funciones de pérdida, podemos mencionar dos que dan lugar a dos modelos diferentes\n",
    "- *Pérdida 0-1*: \n",
    "\n",
    "Por cada punto mal clasificado, sumamos 1 a la funcion de perdida, y por cada punto bien clasificado 0. Esto da lugar al algoritmo conocido como _**Perceptrón**_ de importancia histórica. Esta función de pérdida la podemos escribir como $$\\mathcal{L}(p,y) = \\sum_i max(0; - (2 p_i-1) (2 t_i - 1) )$$\n",
    "donde la predicción del modelo es\n",
    "$$\n",
    "p_i=   \\left\\{\n",
    "    \\begin{array}{ll}\n",
    "    1 & {\\rm if }\\; w_0 + w_1 x^{(i)}_1 + ... + + w_N x^{(i)}_N \\ge 0 \\\\\n",
    "    0 & {\\rm if }\\; w_0 + w_1 x^{(i)}_1 + ... + + w_N x^{(i)}_N < 0 \\\\\n",
    "    \\end{array} \n",
    "    \\right. $$\n",
    "\n",
    "- Entropía cruzada binaria:\n",
    "\n",
    "Esta función de error tiene su origen en la teoría de la información, y es la que caracteriza al modelo del _**Regresor Logístico**_. Se puede escribir como\n",
    "\n",
    "$$\\mathcal{L}(\\vec p, \\vec t) = \\sum_i \\left[ - t_i \\log(p_i) - (1-t_i) \\log(1-p_i)\\right]$$\n",
    "\n",
    "Con la diferencia en que aquí la predicción del modelo $p_i$ no es 0 o 1, sino un número entre 0 y 1, que representa _la probabilidad de que la instancia $x^{(i)}$ pertenezca a la clase 1_."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regresor Logístico"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El regresor logístico es un método discrtiminativo, es decir que nos provee no solo la predicción de _a que clase pertenece una muestra_, sino que responde a la pregunta de _cual es la probabilidad de que una muestra pertenezca a una clase_. Esta probabilidad podrá ser luego usada para clasificar (es decir, usando la probabilidad como función discriminante), donde se asigna cada muestra a la clase más probable (umbral = 0.5) o de otra forma a su elección.\n",
    "\n",
    "Es un _modelo lineal generalizado_, es decir que se basa en un modelo lineal cuyo resultado se pasa por una _función de vínculo_ que en este caso es la función sigmoide. \n",
    "Matemáticamente:\n",
    "$$ p = \\sigma(w_0 + w_1 x^{(i)}_1 + ... + + w_N x^{(i)}_N) $$ \n",
    "\n",
    "siendo $\\sigma $ la función sigmoide $\\sigma(z) = \\frac{1}{1 + e^{-z}}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    return 1 / (1 + np.exp(-z))\n",
    "\n",
    "z = np.linspace(-10,10)\n",
    "plt.plot(z, sigmoid(z))\n",
    "plt.xlabel(\"z\")\n",
    "plt.ylabel(\"$\\sigma (z)$\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A esta parametrización se la aparea con la funcíon de pérdida de _entropía cruzada binaria_ para dar como resultado el regresor logístico. La base matemática de esta elección tiene fundamentos en teoría de la probabilidad, que escapan al marco de esta materia."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ejercicio**\n",
    "\n",
    "1. Use el regresor logístico (importado de Scikit-Learn al comienzo del notebook) para ajustar los datos (setee el parámetro `penalty = 'none'`)\n",
    "\n",
    "*Pistas: El input del modelo X es una matriz cuyas filas son muestras, y cuyas columnas son features. Utilice la funcion `.to_numpy()` de pandas para pasar del DataFrame a arrays de numpy*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Tu turno...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Calcule el vector de probabilidades predichas por el modelo ajustado sobre el dataset. Examine e interprete su resultado.\n",
    "\n",
    "*Pistas: `.predict_proba(X)`*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Tu turno ...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Obtenga los pesos del modelo lineal, utilicelos para graficaar la frontera de decisión\n",
    "\n",
    "*Pistas:*\n",
    "- *Considere los atributos `.coef` y `.intercept_` del regresor logístico.*\n",
    "- *La función sigmoide toca el umbral 0.5 cuando el modelo lineal vale 0, $\\sigma(0)=0.5$. Sabiendo esto, valerse de la función de ploteo utilizada anterioremente*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Tu turno...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Formulario de asistencia\n",
    "\n",
    "Por favor, no olviden completar el siguiente formulario antes del miércoles 05/04 a la 23:59.\n",
    "\n",
    "https://forms.gle/EQ3UMLK1BzaZschU7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extra: Dataset de EcoBicis\n",
    "\n",
    "Utilizando el dataset de la clase anterior (Ecobicis):\n",
    "\n",
    "1. Elija una variable objetivo binaria que considere interesante\n",
    "2. Prepare el dataset para un problema de clasificación. Elija los features, preproceselos y separelos en una matrix `X` de la variable objetivo en un nuevo `t`.\n",
    "3. Entrene un Regresor Logístico sobre el set de datos. \n",
    "4. Evalúe exactitud (porcentaje de predicciones correctas) de su modelo sobre el set de entrenamiento.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tu turno...\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "vscode": {
   "interpreter": {
    "hash": "964b008cb5ef2a660594f048d86c2599bd9046de6f673691130e1855aa2f0225"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
