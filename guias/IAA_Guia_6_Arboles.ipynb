{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Guía 2 - Árboles de Decisión\n",
    "\n",
    "En este notebook trabajaremos con uno de los modelos más difundidos para Aprendizaje Supervisado, Árboles de Decisión. El notebook está dividido en tres partes: \n",
    "\n",
    "1. Construcción de un árbol de decisión *a mano*.\n",
    "1. Titanic + Árboles de Decisión en Scikit-Learn.\n",
    "1. Árboles de Decisión en profundidad.\n",
    "1. Extras.\n",
    "\n",
    "## 1. Construcción de un árbol de decisión *a mano* (Opcional)\n",
    "\n",
    "Es raro que, como Científico de Datos, tengas que programar un modelo, al menos en esta etapa de tu carrera. Como ya sabrás, existen muchas librerías con implementaciones de diferente métodos al alcance de la mano. Sin embargo, hacer una implementación rápida, aunque sea sencilla, ayuda comprender mejor algunos detalles. \n",
    "\n",
    "En esta sección vamos a programar **la consulta** de un árbol de decisión. Todo esto lo implementa Scikit-Learn de forma automática, pero hacerlo te ayudará a comprender mejor los árboles de decisión.\n",
    "\n",
    "Probablemente ya te hayas topado con el dataset de Titanic. Sino, puedes mirarlos en la siguiente competencia Kaggle [Machine Learning from Disaster](https://www.kaggle.com/c/titanic). En la descarga te dejamos una versión simplificada y filtrada de este dataset. Qué representa cada atributo puedes mirarlo en la página de Kaggle, pero te aclaramos que la columna `Sex` refiere al género, donde `0` es hombre y `1` es mujer.\n",
    "\n",
    "**Ejercicio:** Carga el dataset de Titanic y tomate unos minutos para estudiar o recordar sus características. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn import tree\n",
    "\n",
    "df = pd.read_csv(\"IAA_Guia_6_Titanic.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(x='Sex', y='Age', hue='Survived', data=df, alpha=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.displot(x='Age', hue='Survived', data=df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Árbol de decisión *a mano*\n",
    "\n",
    "Ahora sí, manos a la obra.\n",
    "\n",
    "**NOTA**: LEER HASTA EL FINAL ANTES DE MODIFICAR EL CÓDIGO.\n",
    "\n",
    "En primer lugar, vamos a definir algunas funciones que serán de utilidad.\n",
    "\n",
    "* La función `accuracy`, dada las etiquetas que ustedes predigan y las etiquetas reales, calcula la medida de performance, en este caso, la exactitud. **No la tienes que modificar, pero presta atención a su implementación**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(y_predicted, y_real):\n",
    "    mask = np.array(y_predicted) == np.array(y_real)\n",
    "    return mask.sum()/len(y_real)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* La función `predict_instance`, dada una instancia x con sus atributos, predice si sobrevivió o no. **Es la única función que tendrás que modificar**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_instance(x):\n",
    "    '''\n",
    "    Modificar las siguientes líneas de codigo. \n",
    "    Este será su algoritmo algoritmo para predecir si sobrevivirá o no por instancia.\n",
    "    La variable prediction debe contener la etiqueta 0 o 1 \n",
    "    \n",
    "    Algunas opciones son: predecir que nadie sobrevivio, que todos sobrevivieron,\n",
    "    predecir al azar, y usar lo aprendido cuando exploramos el dataset de Titanic\n",
    "    '''\n",
    "    prediction = 0 # cambiar\n",
    "    \n",
    "    ### UNA POSIBLE FORMA DE EMPEZAR:\n",
    "#     if x.Age < 12:\n",
    "#         prediction = 1\n",
    "#     else:\n",
    "#         prediction = 0\n",
    "#     # FIN DE COMPLETAR\n",
    "    \n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Por último, la función `predict` toma todo las instancias `X` y, usando la función que definieron antes, predice para cada una de ellas si sobrevivió o no. **No la tienes que modificar, pero presta atención a su implementación**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(X):\n",
    "    y_predicted = []\n",
    "    for x in X.itertuples(): \n",
    "        y_i = predict_instance(x) \n",
    "        y_predicted.append(y_i)\n",
    "    return y_predicted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Consigna**\n",
    "\n",
    "1. Cargar el dataset de Titanic y separar en una variable `X` los atributos que usarás para predecir, y en una variable `y` la etiqueta que quieres predecir. En este caso, si sobrevivió o no."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(\"Survived\", axis=1)\n",
    "y = df.Survived"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Usar los datos `X` para predecir si los pasajeros sobrevivieron o no utilizando la función `predict`. **No tienes que modificar ninguna de las funciones por ahora**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = predict(X)\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Calcula la medida de performance entre las etiquetas reales `y` y las etiquetas predichas `y_pred` con la función `accuracy`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Accuracy final: \", round(accuracy(y_pred, y), 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Calcula la matriz de confusión con Scikit-Learn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(y, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ejercicio**: modifica `predict_instance` de forma tal de mejorar el resultado recién obtenido. Tal vez te sirva de pista, para arrancar, la famosa frase, \"mujeres y niños primero\".\n",
    "\n",
    "**Para pensar:** las performances asociadas a predecir todos `0` (nadie sobrevivió), todos `1` (todos sobrevivieron), y predecir al azar son muy importantes para evaluar nuestro trabajo. ¿Por qué?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Árboles de Decisión en Scikit-Learn + Titanic\n",
    "\n",
    "Entrena un árbol de decisión de Scikit-Learn en el dataset de Titanic. Algunas recomendaciones:\n",
    "\n",
    "1. Arranca con `max_depth = 2` y fija el `random_state`. Visualiza el árbol obtenido con la función `plot_tree` del módulo `tree` de Scikit-Learn.\n",
    "1. Evalúa su desempeño calculando la exactitud y viendo su matriz de confusión.\n",
    "1. Observa la importancia asignada a cada atributo (`feature_importances_`).\n",
    "1. Si seleccionas dos atributos, pueden observar las fronteras de decisión con código de notebooks anteriores (o luego en este notebook).\n",
    "\n",
    "¿Te parece que lo obtenido concuerda con lo que esperabas?¿Qué puedes aprender de la tragedia del Titanic viendo el árbol de decisíon y la importancia de cada atributo (feature)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creamos un objeto arbol\n",
    "clf = DecisionTreeClassifier(COMPLETAR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "COMPLETAR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (10,8))\n",
    "tree.plot_tree(clf, filled = True, feature_names= X.columns)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importances = clf.feature_importances_\n",
    "columns = X.columns\n",
    "sns.barplot(x=columns, y=importances)\n",
    "plt.title('Importancia de cada Feature')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 3. En profundidad\n",
    "\n",
    "\n",
    "En esta sección del notebook vamos a profundizar en algunas características de los árboles de decisión. En particular, estudiaremos cómo son las fronteras de decisión para un Árbol de Decisión y veremos cómo controlar el sobreajuste.\n",
    "\n",
    "Para ilustrar mejor los conceptos, vamos a recurrir a un dataset sintético de dos clases. Esto facilitará el proceso y nos permitirá visualizar algunos resultados. También dejamos algunas funciones que pueden ser útiles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_classifier(model, X, y, ax=None, cmap='bwr'):\n",
    "    ax = ax or plt.gca()\n",
    "    \n",
    "    # Plot the training points\n",
    "    ax.scatter(X[:, 0], X[:, 1], c=y, s=30, cmap=cmap,\n",
    "               clim=(y.min(), y.max()), zorder=3, alpha = 0.5)\n",
    "    ax.axis('tight')\n",
    "    ax.set_xlabel('x1')\n",
    "    ax.set_ylabel('x2')\n",
    "#     ax.axis('off')\n",
    "    xlim = ax.get_xlim()\n",
    "    ylim = ax.get_ylim()\n",
    "    \n",
    "    xx, yy = np.meshgrid(np.linspace(*xlim, num=200),\n",
    "                         np.linspace(*ylim, num=200))\n",
    "    Z = model.predict(np.c_[xx.ravel(), yy.ravel()]).reshape(xx.shape)\n",
    "\n",
    "    # Create a color plot with the results\n",
    "    n_classes = len(np.unique(y))\n",
    "    contours = ax.contourf(xx, yy, Z, alpha=0.3,\n",
    "                           levels=np.arange(n_classes + 1) - 0.5,\n",
    "                           cmap=cmap, clim=(y.min(), y.max()),\n",
    "                           zorder=1)\n",
    "\n",
    "    ax.set(xlim=xlim, ylim=ylim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_blobs\n",
    "\n",
    "X, y = make_blobs(n_samples=1000, centers=2,\n",
    "                  random_state=0, cluster_std=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(X[:, 0], X[:, 1], c=y, s=25, cmap='bwr')\n",
    "plt.colorbar()\n",
    "plt.xlabel('x1')\n",
    "plt.ylabel('x2')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Para pensar:** observa el gráfico obtenido y evalúa si, dada únicamente los atributos del gráfico, es posible obtener un clasificador perfecto (exactitud 1).\n",
    "\n",
    "\n",
    "**Train-test split**\n",
    "\n",
    "Hasta ahora lo hemos omitido, pero vamos a hacer un `train_test_split` de los datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Sobreajuste y Regularización\n",
    "\n",
    "\n",
    "**Ejercicio:** \n",
    "\n",
    "1. Observa y familiarizate con los argumentos de un `DecisionTreeClassifier`. Presta particular atención a `max_depth`.\n",
    "1. Por defecto, un `DecisionTreeClassifier` de Scikit-Learn no tiene regularización. El árbol va a crecer hasta que consiga una perfecta separación de clases. Entonces, entrena un Árbol de Decisión sin ningún tipo de regularización. Para ello, utiliza los argumentos por defecto.\n",
    "1. Evalúalo en train y test, y grafica las fronteras de decisión usando la función `visualize_classifier`. ¿Qué te parece que puedes decir sobre estas fronteras?¿Te parece que hay sobreajuste?\n",
    "1. Grafica el árbol usando la función `plot_tree`. ¿Alguna señal de alerta?\n",
    "\n",
    "**Ejercicio:** Entrena los modelo, pero ahora poniendo valores predeterminados en `max_depth`. Por ejemplo, 1, 3 y 5. ¿Puedes decir algo sobre el desempeño en train y test?¿Y sobre las fronteras?\n",
    "\n",
    "**Ejercicio:** Haz un gráfico de desempeño en train y test en función de `max_depth`. Interpreta.\n",
    "\n",
    "\n",
    "**Ejercicio:** Hay muchas formas de controlar el sobreajuste en un árbol de decisión. Leé en la documentación qué hacen los siguientes argumentos:\n",
    "* `max_depth`\n",
    "* `min_samples_split`.\n",
    "* `min_samples_leaf`\n",
    "* ``min_samples_leaf` \n",
    "* `max_leaf_nodes`:     \n",
    "* `min_impurity_decrease`\n",
    "\n",
    "Luego:\n",
    "* Elije al menos tres de esos hiperparámetros\n",
    "* Entrena árboles de decisión para distintas combinaciones de valores de esos hiperparámetros. \n",
    "* Visualice los árboles resultantes y la frontera de decisión para obtener información sobre el procedimiento de regularización."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = COMPLETAR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "COMPLETAR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_classifier(clf, X, y, ax=None, cmap='bwr')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_depths = np.arange(1,20)\n",
    "acc_train = []\n",
    "acc_test = []\n",
    "for COMPLETAR in COMPLETAR:    \n",
    "    clf = DecisionTreeClassifier(COMPLETAR)\n",
    "    COMPLETAR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(COMPLETAR)\n",
    "COMPLETAR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Fronteras de decisión cartesianas\n",
    "\n",
    "Si observaste atentamente las fronteras obtenidas por los árboles de decisión, tal vez te llamó la atención cierta característica. Un árbol puede, en principio, aproximar cualquier frontera entre clases. Pero cada división es obtenida sobre un atributo a la vez, por lo que esto se traduce en fronteras con segmentos verticales u horizontales. Entonces, la el resultado está fuertemente influencia por la orientación de los atributos. Veámoslo con un ejemplo.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#First class: 250 points that follow a bi-normal distribution\n",
    "size1 = 50\n",
    "mu1 = [0, 0]\n",
    "cov1 = [[1, 0],[0, 1]]\n",
    "\n",
    "#Second class: 200 points that follow a bi-normal distribution\n",
    "size2 = 50\n",
    "mu2 = [4, 0]\n",
    "cov2 = [[1, 0],[0, 1]]\n",
    "\n",
    "np.random.seed(42)\n",
    "# Sample classes\n",
    "xc1 = np.random.multivariate_normal(mean=mu1, cov=cov1, size=size1).T\n",
    "xc2 = np.random.multivariate_normal(mean=mu2, cov=cov2, size=size2).T\n",
    "\n",
    "#targets: 1 and -1\n",
    "yc1 = np.ones((1, xc1.shape[1]))\n",
    "yc2 = np.zeros((1, xc2.shape[1]))\n",
    "\n",
    "#We stack them in a single vector\n",
    "x = np.hstack([xc1, xc2]).T\n",
    "y = np.hstack([yc1, yc2]).ravel()\n",
    "\n",
    "plt.scatter(x[y==0][:,0], x[y==0][:,1], label='class 1')\n",
    "plt.scatter(x[y==1][:,0], x[y==1][:,1], label='class 2')\n",
    "\n",
    "plt.xlim(-4,8)\n",
    "plt.ylim(-4,8)\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este conjunto de datos es linealmente separable y los grupos se separan con una frontera paralela a uno de los atributos. Entrenemos un `DecisionTreeClassifier` en este dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_clf = DecisionTreeClassifier()\n",
    "tree_clf.fit(x,y)\n",
    "\n",
    "tree.plot_tree(tree_clf, filled=True, rounded=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The resulting tree is really simple, as it is the clasification boundary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_classifier(tree_clf,x,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora, podemos rotar los atributos en el espacio. Si bien esto puede parecer, en principio, raro, veremos más adelante que es algo completamente natural y que, de hecho, se suele hacer (de hecho, se suele hacer con el objetivo contrario al que lo haremos nosotros)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_rotated = np.zeros(x.shape)\n",
    "x_rotated[:,0] = x[:,0]+x[:,1]\n",
    "x_rotated[:,1] = x[:,0]-x[:,1]\n",
    "\n",
    "plt.scatter(x_rotated[y==0][:,0], x_rotated[y==0][:,1], label='class 1')\n",
    "plt.scatter(x_rotated[y==1][:,0], x_rotated[y==1][:,1], label='class 2')\n",
    "\n",
    "plt.xlim(-4,8)\n",
    "plt.ylim(-4,8)\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora, el conjunto de datos sigue siendo linealmente separable, pero la frontera de decisión ya no está alineada con ninguno de los atributos. Veamos el árbol de decisión resultante."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rotated_tree_clf = DecisionTreeClassifier()\n",
    "rotated_tree_clf.fit(x_rotated,y)\n",
    "\n",
    "plt.figure(figsize=(5,8))\n",
    "tree.plot_tree(rotated_tree_clf, filled=True, rounded=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Que arroja la siguiente frontera de decisión."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_classifier(rotated_tree_clf,x_rotated,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Como podemos ver, es mucho más difícil para un Árbol de Decisión aprender regiones que no están alineadas con los atributos.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extras: Cálculo de Impureza y Ganancia Gini\n",
    "\n",
    "Ahora vamos a calcular cuán buena es la *pregunta* del género y clase del Titanic para separar las muestras usando la impureza Gini. Para ello:\n",
    "\n",
    "**Ejercicio:** calcula la impureza inicial del dataset. Ayuda: recuerda que en la variable `y` ya separaste las etiquetas. Si es un objeto de Pandas, tal vez la función `value_counts()` puede ser útil.\n",
    "\n",
    "Por las dudas, volvemos a cargar el dataset y definir la variables `x` e `y`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"IAA_Guia_6_Titanic.csv\")\n",
    "X = df.drop(\"Survived\", axis=1)\n",
    "y = df.Survived"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "muestras_neg, muestras_pos = y.value_counts()\n",
    "N = y.size\n",
    "gini_inicial = COMPLETAR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(gini_inicial)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ejercicio:** calcula la impureza Gini luego de separar por el género. Recuerden que tienen que calcular la impureza en dos hojas - una correspondiente a género masculino y otra al femenino - y luego hacer un promedio ponderado. Para eso, puede ser conveniente crear una máscara y reciclar código anterior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mascara = df.Sex == 1\n",
    "y_female = y[mascara]\n",
    "y_male = y[~mascara]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "COMPLETAR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "COMPLETAR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Impureza Gini al separar por Genero:',(y_female.size*COMPLETAR + y_male.size*COMPLETAR)/y.size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ejercicio Opcional:** calcula la impureza Gini luego de separar por clase. Recuerden que tienen que calcular la impureza en tres hojas y luego hacer un promedio ponderado. Para eso, puede ser conveniente crear tres máscaras y reciclar código anterior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mascara = df.Pclass == 1\n",
    "y_1 = y[mascara]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "COMPLETAR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mascara = df.Pclass == 2\n",
    "COMPLETAR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "COMPLETAR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mascara = df.Pclass == 3\n",
    "COMPLETAR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "COMPLETAR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Impureza Gini al separar por clase:', COMPLETAR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**¿Cuál tiene una mayor ganancia Gini?¿Concuerda con lo visto hasta ahora?**\n",
    "\n",
    "**Para pensar:** ¿cómo modificarías el código para calcular la ganancia Gini al separar por edad? Por ejemplo, al separar por mayor de 12 años y menor de 12 años.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Formulario de Asistencia\n",
    "\n",
    "Obligatorio completar antes del Miercoles 3 de Mayo a las 23:59\n",
    "https://forms.gle/y73u31jTmXtZyMsR8"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
